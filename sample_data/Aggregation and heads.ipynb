{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation for 15 km (9 grids of 5 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import calendar\n",
    "import datetime\n",
    "from numpy  import array\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the climate variables into a single file (define coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify latitude of the left top corner in the grid to aggregate\n",
    "a=-43.25\n",
    "#Specify longitude of the left top corner in the grid to aggregate\n",
    "b=146.90\n",
    "#Some calculation...\n",
    "a2=round(a-0.05,2)\n",
    "a3=round(a-0.1,2)\n",
    "b2=round(b+0.05,2)\n",
    "b3=round(b+0.1,2)\n",
    "\n",
    "#Defining the ranges\n",
    "lat_range=[a3,a2,a]\n",
    "lon_range=[b,b2,b3]\n",
    "\n",
    "dirname= r'C:\\Users\\jjojeda.000\\Dropbox\\DATA\\APSIM sim\\base climate data'\n",
    "\n",
    "#Merge individuals variables into a single file\n",
    "def generate_dataframe(lat_range, lon_range, download_files=False, output_to_file=True, create_met=False):\n",
    "\n",
    "    for lat in lat_range:\n",
    "\n",
    "            for lon in lon_range:\n",
    "                \n",
    "                df1= pd.read_csv(os.path.join(dirname,'{}-{}-{}.met'.format(\"radiation\",lat,lon)))\n",
    "                df2= pd.read_csv(os.path.join(dirname,'{}-{}-{}.met'.format(\"max_temp\",lat,lon)))\n",
    "                df3= pd.read_csv(os.path.join(dirname,'{}-{}-{}.met'.format(\"min_temp\",lat,lon)))\n",
    "                df4= pd.read_csv(os.path.join(dirname,'{}-{}-{}.met'.format(\"daily_rain\",lat,lon)))\n",
    "                df5=df1.merge(df2)\n",
    "                df6=df5.merge(df3)\n",
    "                dffinal=df6.merge(df4)\n",
    "\n",
    "                #Change name of variables\n",
    "                dffinal.rename(columns={'radiation': 'radn','max_temp': 'maxt','min_temp': 'mint','daily_rain': 'rain'}, inplace=True)\n",
    "\n",
    "                #Delete the head of the following years\n",
    "                dffinal2=dffinal[dffinal.year != 'year']\n",
    "\n",
    "                #Export combined csv\n",
    "                dffinal2.to_csv('{}-{}.met'.format(lat,lon), sep=\" \", index=False, mode=\"a\")\n",
    "                \n",
    "generate_dataframe(lat_range=lat_range, lon_range=lon_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the aggregated climate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some explanation:\n",
    "#for a given grid of 15*15km, we have the corresponding coordinates:\n",
    "#lat_range=[-39.8,-39.75,-39.7] == lat_range=[0,1,2]\n",
    "#lon_range=[143.85,143.9,143.95] == lon_range=[0,1,2]\n",
    "\n",
    "#Open grid files\n",
    "f1 = pd.read_csv('{}-{}.met'.format(lat_range[0],lon_range[0]), sep=\" \", index_col=False)\n",
    "f2 = pd.read_csv('{}-{}.met'.format(lat_range[0],lon_range[1]), sep=\" \", index_col=False)  \n",
    "f3 = pd.read_csv('{}-{}.met'.format(lat_range[0],lon_range[2]), sep=\" \", index_col=False)  \n",
    "f4 = pd.read_csv('{}-{}.met'.format(lat_range[1],lon_range[0]), sep=\" \", index_col=False)  \n",
    "f5 = pd.read_csv('{}-{}.met'.format(lat_range[1],lon_range[1]), sep=\" \", index_col=False)  \n",
    "f6 = pd.read_csv('{}-{}.met'.format(lat_range[1],lon_range[2]), sep=\" \", index_col=False)  \n",
    "f7 = pd.read_csv('{}-{}.met'.format(lat_range[2],lon_range[0]), sep=\" \", index_col=False)  \n",
    "f8 = pd.read_csv('{}-{}.met'.format(lat_range[2],lon_range[1]), sep=\" \", index_col=False)  \n",
    "f9 = pd.read_csv('{}-{}.met'.format(lat_range[2],lon_range[2]), sep=\" \", index_col=False)  \n",
    "\n",
    "#Merge grids files\n",
    "merged_table=pd.concat([f1,f2,f3,f4,f5,f6,f7,f8,f9], axis=1, sort=False)\n",
    "\n",
    "#Calculate average of each variable across the grid files\n",
    "merged_table['radn_avg'] = merged_table[['radn']].mean(axis=1).round(decimals=1)\n",
    "merged_table['maxt_avg'] = merged_table[['maxt']].mean(axis=1).round(decimals=1)\n",
    "merged_table['mint_avg'] = merged_table[['mint']].mean(axis=1).round(decimals=1)\n",
    "merged_table['rain_avg'] = merged_table[['rain']].mean(axis=1).round(decimals=1)\n",
    "\n",
    "#Delete undesirable columns \n",
    "merged_table.drop(columns=['radn','maxt','mint','rain'], axis=1, inplace=True)\n",
    "\n",
    "#Delete duplicated columns\n",
    "merged_table = merged_table.loc[:,~merged_table.columns.duplicated()]\n",
    "\n",
    "#Change name of variables\n",
    "merged_table.rename(columns={'radn_avg': 'radn','maxt_avg': 'maxt','mint_avg':'mint','rain_avg':'rain'}, inplace=True)\n",
    "\n",
    "#Remove rubbish\n",
    "os.remove('{}-{}.met'.format(lat_range[0],lon_range[0]))\n",
    "os.remove('{}-{}.met'.format(lat_range[0],lon_range[1]))\n",
    "os.remove('{}-{}.met'.format(lat_range[0],lon_range[2]))\n",
    "os.remove('{}-{}.met'.format(lat_range[1],lon_range[0]))\n",
    "os.remove('{}-{}.met'.format(lat_range[1],lon_range[1]))\n",
    "os.remove('{}-{}.met'.format(lat_range[1],lon_range[2]))\n",
    "os.remove('{}-{}.met'.format(lat_range[2],lon_range[0]))\n",
    "os.remove('{}-{}.met'.format(lat_range[2],lon_range[1]))\n",
    "os.remove('{}-{}.met'.format(lat_range[2],lon_range[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the final apsim met file (including head, amp and tav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.98372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Creating the head for the met apsim file:\n",
    "\n",
    "#Get the months as a column\n",
    "merged_table = merged_table.convert_objects(convert_numeric=True)\n",
    "merged_table['cte']=1997364\n",
    "merged_table['day2']=merged_table['day']+merged_table['cte']\n",
    "merged_table['date'] = (pd.to_datetime((merged_table.day2 // 1000)) + pd.to_timedelta(merged_table.day2 % 1000, unit='D'))\n",
    "merged_table['month'] = merged_table.date.dt.month\n",
    "month=merged_table.loc[:,'month']\n",
    "\n",
    "#Calculate amp\n",
    "merged_table['tmean'] = merged_table[['maxt', 'mint']].mean(axis=1)\n",
    "tmeanbymonth=merged_table.groupby(month)[[\"tmean\"]].mean()\n",
    "maxmaxtbymonth=tmeanbymonth.loc[tmeanbymonth['tmean'].idxmax()].round(decimals=5)\n",
    "minmaxtbymonth=tmeanbymonth.loc[tmeanbymonth['tmean'].idxmin()].round(decimals=5)\n",
    "a=maxmaxtbymonth-minmaxtbymonth\n",
    "b=list(a)\n",
    "am=array(b).round(decimals=5)\n",
    "for i in am:\n",
    "    print(i)\n",
    "\n",
    "#Calculate tav\n",
    "#tav=merged_table[\"tmean\"].mean()\n",
    "tav=tmeanbymonth.groupby(month)[[\"tmean\"]].mean().round(decimals=5)\n",
    "z=tav.iloc[0]['tmean']\n",
    "\n",
    "#Delete some rubbish\n",
    "merged_table.drop(merged_table.columns[[6, 7, 8, 9, 10]], axis=1, inplace=True)\n",
    "\n",
    "#Add variables units:\n",
    "#create series from types_header_for_insert\n",
    "merged_final_file = pd.DataFrame(columns = merged_table.columns)\n",
    "s = pd.Series([\"()\",\"()\",\"(MJ^m2)\",\"(oC)\",\"(oC)\",\"(mm)\"], index=merged_table.columns)\n",
    "merged_final_file = merged_final_file.append(s, ignore_index=True).append(merged_table, ignore_index=True)\n",
    "\n",
    "#Write head of file\n",
    "with open('{}-{}.met'.format(lat_range[2],lon_range[0]),'a') as file:\n",
    "        file.write('[weather.met.weather]\\n')\n",
    "        file.write('                         !station number={}-{}\\n'.format(lat_range[2],lon_range[0]))\n",
    "        file.write('                         Latitude={}\\n'.format(lat_range[2]))\n",
    "        file.write('                         Longitude={}\\n'.format(lon_range[0]))\n",
    "        file.write('                         tav={}\\n'.format(z))\n",
    "        file.write('                         amp={}\\n\\n'.format(i))\n",
    "        \n",
    "#Export combined csv\n",
    "merged_final_file.to_csv('{}-{}.met'.format(lat_range[2],lon_range[0]), sep=\" \", index=False, mode=\"a\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
